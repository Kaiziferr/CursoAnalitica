{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN: K-Nearest Neighbors + Protocolos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerías que vamos a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #operaciones matriciales y con vectores\n",
    "import pandas as pd #tratamiento de datos\n",
    "import matplotlib.pyplot as plt #gráficos\n",
    "from sklearn import neighbors, datasets, metrics\n",
    "from sklearn.model_selection import train_test_split #metodo de particionamiento de datasets para evaluación\n",
    "from sklearn.model_selection import cross_val_score, cross_validate #método para evaluar varios particionamientos de C-V\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RepeatedKFold, LeaveOneOut #Iteradores de C-V\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ignorar los warnings que no son importantes para lo que vamos a hacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendimiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos para entenderlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset esta guardado en una clase de scikit-learn llamada Bunch. Vamos a ver como accedemos a los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"variables independientes: \", iris.feature_names, iris.data.shape)\n",
    "print(\"variable dependiente: \", iris.target_names, iris.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una sola estructura con todos los datos para poder visualizarlos más fácilmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data\n",
    "y = iris.target\n",
    "y = np.expand_dims(y, axis=1)\n",
    "data = np.concatenate((x, y), axis = 1)\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.squeeze(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data)\n",
    "labels = iris.feature_names.copy()\n",
    "labels.append('species')\n",
    "d.columns=labels\n",
    "d['species'] = d['species'].astype(int).astype('str')\n",
    "#str(d['species'])\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación a partir de K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo de K-NN requiere la especificación del parámetro K, con el número de vecinos que se considerarán para tomar la decisión de clasificación (recuerden que K-NN también permite hacer regresión).\n",
    "\n",
    "A partir de las cuatro variables independientes (largo y ancho de pétalo y de sépalo), vamos a determinar la especie de la flor usando K-NN.\n",
    "Definimos un valor de K=5 y utilizamos el mismo dataset de 150 instancias para evaluar los resultados del algoritmo (las clases predichas), comparándolos con los reales (especies reales de cada registro).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos el modelo \"aprendido\" con el dataset de 150 instancias de Iris.\n",
    "Vamos ahora a evaluarlo sobre ese mismo dataset para poder ver los éxitos y errores de la predicción. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(x)\n",
    "print(\"Clases reales   : \", y)\n",
    "print(\"Clases predichas: \", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas y matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay unos cuantos errores, para poder analizar mejor los resultados, vamos a construir una matriz de confusión y a aplicar métricas de clasificación.\n",
    "\n",
    "En las filas quedarán las clases reales, en las columnas las predichas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm= metrics.confusion_matrix(y, y_pred)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title(\"Matriz de confusión para K=5\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(3)\n",
    "plt.xticks(tick_marks, iris.target_names)\n",
    "plt.yticks(tick_marks, iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Realice las siguientes tareas (para poder hacerlas utilicen cuando puedan sklearn.metrics, sin embargo, para ciertas métricas, es necesario realizar los cálculos a mano):</font>\n",
    "\n",
    "1. <font color='red'>Obtenga e interprete los resultados de exactitud y kappa.</font>\n",
    "\n",
    "2. <font color='red'>Para cada una de las clases, calculen e interpreten los valores de las métricas de precisión, recall, especificidad, f1 score.</font>\n",
    "\n",
    "3. <font color='red'>Intenten con otros valores de K, y encuentren el mejor modelo K-NN.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)\n",
    "print(\"Exactitud: \", metrics.accuracy_score(y, y_pred))\n",
    "print(\"Kappa    : \", metrics.cohen_kappa_score(y, y_pred))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Metricas para la categoría \", iris.target_names[0])\n",
    "print(\"Precisión     : \", metrics.precision_score(y, y_pred, labels=[0], average='macro'))\n",
    "print(\"Recall        : \", metrics.recall_score(y, y_pred, labels=[0], average='macro'))\n",
    "VN = np.sum(cm[1:3,1:3])\n",
    "FP = np.sum(cm[0,1:3])\n",
    "specificity = VN/(VN+FP)\n",
    "print(\"Especificidad : \", specificity)\n",
    "print(\"F1-score      : \", metrics.f1_score(y, y_pred, labels=[0], average='macro'))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Metricas para la categoría \", iris.target_names[1])\n",
    "print(\"Precisión     : \", metrics.precision_score(y, y_pred, labels=[1], average='macro'))\n",
    "print(\"Recall        : \", metrics.recall_score(y, y_pred, labels=[1], average='macro'))\n",
    "VN = 98\n",
    "FP = 2\n",
    "specificity = VN/(VN+FP)\n",
    "print(\"Especificidad : \", specificity)\n",
    "print(\"F1-score      : \", metrics.f1_score(y, y_pred, labels=[1], average='macro'))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Metricas para la categoría \", iris.target_names[2])\n",
    "print(\"Precisión     : \", metrics.precision_score(y, y_pred, labels=[2], average='macro'))\n",
    "print(\"Recall        : \", metrics.recall_score(y, y_pred, labels=[2], average='macro'))\n",
    "VN = np.sum(cm[0:2,0:2])\n",
    "FP = np.sum(cm[2,0:2])\n",
    "specificity = VN/(VN+FP)\n",
    "print(\"Especificidad : \", specificity)\n",
    "print(\"F1-score      : \", metrics.f1_score(y, y_pred, labels=[2], average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtuvimos un muy buen nivel de exactitud del 96.7% evaluando sobre el mismo set de aprendizaje.\n",
    "Ademas muy buenos scores globales para todas las clases. De hecho, la clase setosa se pudo tratar a la perfección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intentemos con otros valores de  K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks=[1,3,5,7,9,11]\n",
    "for k in ks:\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x, y)\n",
    "    y_pred = knn.predict(x)\n",
    "    print(\"Con K = \", k, \", exactitud: \", metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados anteriores nos llevarían a pensar que con K=1 se obtiene un modelo con una predicción \"perfecta\".\n",
    "\n",
    "Como lo veremos a continuación. Este no es para nada el caso, pues estamos violando una de las máximas de la evaluación de los modelos de aprendizaje supervisado: evaluar sobre el mismo set de entrenamiento.\n",
    "\n",
    "Esta evaluación produce resultados que subestiman el error de aprendizaje, y no da una indicación clara del poder de generalización del modelo sobre datos diferentes a los encontrados durante el proceso de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocolos de evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ahora a evaluar los modelos que calculamos con diferentes protocolos de evaluación para tener una idea más clara de la calidad de los mismos, e identificar posibles casos de modelos que sufren de overfitting (sobreaprendizaje)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout (split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a separar el dataset en 2 partes: 60% de los datos se van a utilizar para aprender, 40% para evaluar el modelo de clasificación.\n",
    "Utilizamos el método *train_test_split* de scikit-learn, que se encarga de hacer el particionamiento aleatorio: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=12345, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros de este método son:\n",
    "- train_size o test_size: define la proporción del dataset que se irán al training set o al test set.\n",
    "- random_state: define la **semilla** a utilizar para incializar el generador de números pseudo-aleatorios. Se requiere que los resultados obtenidos con la partición sean eventualmente reproducibles. La semilla aleatoria debe inicalizarse en el mismo valor para obtener los mismos resultados.\n",
    "- stratify: indica un array con los valores de una variable que se quiere tener en cuenta en el particionamiento, de tal manera que las proporciones originales se conserven después de la partición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vec= np.arange(1,31,2)\n",
    "k_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_vec=[]\n",
    "acc_test_vec=[]\n",
    "k_vec= np.arange(1,31,2)\n",
    "for k in k_vec:\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_train)\n",
    "    acc_train_vec.append(metrics.accuracy_score(y_train, y_pred))\n",
    "    y_pred = knn.predict(X_test)\n",
    "    acc_test_vec.append(metrics.accuracy_score(y_test, y_pred))\n",
    "print(acc_train_vec)\n",
    "print(acc_test_vec)\n",
    "print(k_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "ax = plt.gca() # get current axis\n",
    "plt.plot(k_vec, acc_train_vec)\n",
    "plt.plot(k_vec, acc_test_vec)\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.axis('tight')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Evolución de le exactitud vs complejidad del modelo k-nn (valor de k más pequeño)')\n",
    "plt.legend(['train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que con k=1, encontramos la mayor tasa de exactitud cuando se valua con el training set, pero con el test set hallamos el mejor desempeño con k=3.\n",
    "\n",
    "Hay que tener en cuenta que estos resultados se obtuvieron con un mismo particionamiento aleatorio, que esta muy sujeto a incertidumbre. ¿Qué pasaría si se repite este procedimiento con otros particionamientos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**TODO:** Realicen varias particiones aleatorias con las mismas proporciones y evalúe los resultados del modelo.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este protocolo de evaluación consiste en dividir el dataset en K pedazos de igual tamaño, y analizar el rendimiento de un modelo aprendido que va rotando sobre k-1 subconjuntos y evaluado en el subconjunto faltante (El K del K-fold no tiene niguna relación con el K del K-NN). \n",
    "En el caso de clasificación, particionamiento se hace aleatoriamente y de manera estratificada con respecto a la variable objetivo.\n",
    "Las métricas finales son las agregaciones de las evaluaciones de los K modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*scikit-learn* conta con una función que permite repetir el proceso de particionamiento y evaluación del K-fold CV. Se trata de **cross_val_score**, que recibe los siguientes parámetros:\n",
    "- la instancia del modelo que se quiere evaluar, \n",
    "- los datos de las variables independiente, \n",
    "- los datos reales de la variable dependiente, \n",
    "- cv: el número de veces que se va a repetir el proceso de cross-validation\n",
    "- scoring: la métrica que se desea evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "exactitudes = cross_val_score(knn, x, y, cv=10, scoring='accuracy')\n",
    "exactitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los scores de las 10 iteraciones del CV dan resultados entre 86.7% y 100%. Podemos obtener un intervalo de confianza del 95% para estimar el valor de la exactitud generalizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exactitudes: %0.2f (+/- %0.2f)\" % (exactitudes.mean(), exactitudes.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema es que con este método solo se puede evaluar una sola métrica a la vez, y que debe ser una métrica global, o tratar una clasificación binaria.\n",
    "\n",
    "El método **cross_validate** permite evaluar mas de una métrica a la vez, pero en el caso de categorías que no sean binarias, las métricas de precision, recall y f1 son agregadas. La salida de este método es un directorio con las métricas resultantes, que además incluye el tiempo de aprendizaje y de evaluación de cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "scores = cross_validate(knn, x, y, scoring=scoring, cv=10, return_train_score=False)\n",
    "\n",
    "for key in scores:\n",
    "    score = scores[key]\n",
    "    print(\"%s: %0.2f (+/- %0.2f)\" % (key, score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteradores de cross-validation: KFold, StratifiedKFold, LeaveOneOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos utilizar también clases específicas para los particionamientos de los datos que permiten mucha más flexibilidad. Las clases **KFold**, **RepeatedKFold**, y **LeaveOneOut** se limitan a crear iteradores que retornan los subconjuntos de training y test.\n",
    "\n",
    "Es importante anotar que estos iteradores parten del supuesto de independencia de los registros, por lo que es necesario barajarlos previamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFold solo particiona los datos en subconjuntos de items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "acc_test_vec=[]\n",
    "for indices_train, indices_test in kf.split(x):\n",
    "    #print(\"%s %s\" % (indices_train, indices_test))\n",
    "    knn.fit(x[indices_train], y[indices_train])\n",
    "    y_pred = knn.predict(x[indices_test])\n",
    "    acc_test_vec.append(metrics.accuracy_score(y[indices_test], y_pred))  \n",
    "acc_test_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un caso particular es cuando el K del KFold es igual al tamaño de la muestra. En tal caso, se obtiene un protocolo de LeaveOneOut. En este caso los resultados para cada test set (de tamaño 1) solo pueden ser del 100% o del 0%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "loocv = LeaveOneOut()\n",
    "acc_test_vec=[]\n",
    "for indices_train, indices_test in loocv.split(x):\n",
    "    #print(\"%s %s\" % (indices_train, indices_test))\n",
    "    knn.fit(x[indices_train], y[indices_train])\n",
    "    y_pred = knn.predict(x[indices_test])\n",
    "    acc_test_vec.append(metrics.accuracy_score(y[indices_test], y_pred))  \n",
    "np.mean(acc_test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una mejora se logra con el StratifiedKFold, pues se tiene en cuenta las proporciones de la variable objetivo en la partición, controlando un poco un posible sesgo en la aleatoriedad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "acc_test_vec=[]\n",
    "for indices_train, indices_test in kf.split(x, y):\n",
    "    knn.fit(x[indices_train], y[indices_train])\n",
    "    y_pred = knn.predict(x[indices_test])\n",
    "    acc_test_vec.append(metrics.accuracy_score(y[indices_test], y_pred))  \n",
    "acc_test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
