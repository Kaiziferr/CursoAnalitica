{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analítica de datos\n",
    "# Examen parcial 1\n",
    "# 2019-02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'> Julio Cesar Gaviria Jaramillo, A00305816 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>ENTREGA PRIMERA PARTE</font> - <font color='blue'> EN CLASE </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usted es el encargado de analítica de una empresa de telefonía celular y tiene que proporcionar soluciones para hacer frente a las problemáticas de un sector que ha llegado a saturación del mercado. Tanto su empresa como sus competidores directos tienen que disputarse por una base de clientes limitada, de tal forma que usted tiene que responder a un objetivo estratégico definido por la dirección así:  \n",
    "\n",
    "    \"Mantener y fidelizar a nuestros clientes por medio de un servicio de calidad que se adapte a sus necesidades particulares.\"\n",
    "    \n",
    "Su compañía dispone de una base de datos histórica de personas que hace un año eran clientes propios. Algunos de esos clientes siguen siéndolo hoy en día, otros ya no lo son. La idea es podeer identificar los clientes que son propensos a dejar la compañía, para poder pensar en programas de fidelización preventivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los campos del dataset son los siguientes:\n",
    "1.  ID: Código identificador de los clientes de la compañía de telefonía móvil\n",
    "1.\tESTADO: Describe si el usuario sigue con la compañía (VINCULADO) o no (RETIRADO)\n",
    "1.\tINGRESOS: Promedio de ingresos del cliente en pesos\n",
    "1.\tCASA: Precio de la casa en la que vive el cliente en pesos\n",
    "1.\tPRECIO_DISPOSITIVO: Precio del celular del cliente en pesos\n",
    "1.  GÉNERO: \"Hombre\" o \"Mujer\"\n",
    "1.\tMESES: Antigüedad del usuario en meses\n",
    "1.\tDURACION: Promedio de duración de las llamadas hechas por el cliente en minutos\n",
    "1.\tSOBRECARGO: Promedio de minutos que se sobrepasa el usuario en un mes\n",
    "1.\tSALDO_RESTANTE: Promedio de minutos de su plan que le quedan al usuario sin utilizar cada mes\n",
    "1.\tSATISFACCION: nivel de satisfacción del usuario de 0 a 10 (muy satisfecho), obtenido a partir de una encuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea es poder predecir el ESTADO a partir de las otras variables, utilizando modelos de aprendizaje supervisado (KNN, NaiveBayes, y regresión logística)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Entendimiento de los datos, limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo \"DatosTelco.csv\" contiene el dataset que tienen que analizar.\n",
    "Se recomienda abrirlo primero en un lector de archivos planos para entender preliminarmente su formato y así poderlo cargar adecuadamente con Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta el tipo de problema en cuestión (clasificación o regresión), realice un análisis exploratorio de los datos estableciendo el baseline, verificando la calidad de los datos (tipos de las variables, valores inválidos, excepciones, valores faltantes, etc.), utilizando gráficos para poder entender las distribuciones de los datos e identificar posibles problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta lo siguiente: \n",
    "- para modificar ciertos valores de un dataframe, se utiliza \"df.replace('oldvalue', 'newvalue')\", si se trata de un valor NaN, se utiliza *np.nan* (ya sea el oldvalue o el newvalue)\n",
    "- para cambiar un tipo de dato a numérico en una estructura de pandas, se utiliza su método \".astype('float64')\"\n",
    "- para negar una condición en python se utiliza el símbolo \"~\"\n",
    "- para obtener una tabla de frecuencias de los registros (filas) con respecto al valor de una variable categórica se utiliza \"pd.crosstab(index=df['var'], columns=\"conteo\")\n",
    "- para cambiar los valores de una columna en un dataframe con condiciones, utilizar \"df.loc[condicion, 'columna']=newVal\"\n",
    "- cuando haya atributos con demasiados valores faltantes, pueden eliminar la columna correspondiente.\n",
    "- cuando haya atributos con unos pocos valores faltantes, pueden eliminar los registros correspondientes.\n",
    "- cuando el número de valores faltantes de un atributo no sea tan elevado, pero si sea considerable, pueden reemplazar los valores faltantes:\n",
    "  - Si se trata de una variable categórica, pueden crear un nuevo valor, o reemplazar por la categoría más común\n",
    "  - Si se trata de una variable numérica, pueden reemplazar por el promedio de los valores presentes del atributo\n",
    "- cuando se quiere ordenar un dataframe por los valores de una columna se usa \"df.sort_values(\"COLUMNA\", ascending=True)\"\n",
    "- para borrar los registros a partir de un índice de fila se utiliza \"df.drop([0,3])\"\n",
    "- para borrar los registros a partir de una condición se utiliza \"df = df[df.edad<99]\"\n",
    "- para borrar una columna por nombre se utiliza --> df = df.drop('columna',axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Puntos a desarrollar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DURANTE EL EXAMEN, EN CLASE: \n",
    "1. <font color='red'>Carguen el archivo en memoria y exploren los datos. Antes de hacer limpieza identifiquen, el baseline global (0.1) y los baselines por GÉNERO (0.2).\n",
    "   ¿A primera vista, solo considerando el género, cree que es una buena idea crear un modelo predictivo de la deserción de hombres y de mujeres de manera separada? (0.2).</font>\n",
    "2. <font color='red'>Identifiquen los problemas e inconsistencias que tienen los datos, teniendo en cuenta el diccionario de datos y el contexto del problema. Limpien los datos, argumentando las razones de cada transformación o eliminación de datos.\n",
    "(1.1). </font>\n",
    "\n",
    "EN CASA, PARA ENTREGAR: \n",
    "3. <font color='red'>Para arreglar un problema existente en la variable CASA: (1.0)\n",
    "    * utilice un modelo de regresión lineal (use el modelo sklearn.linear_model.LinearRegression, no use statsmodels)\n",
    "    * considere solo las demas variables NUMÉRICAS como variables predictivas\n",
    "    * cree el mejor modelo que utilice 1 solo variable, calcule el R2 ajustado e interprételo\n",
    "    * utilice holdout (70/30) como protocolo de evaluación\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Carga y baselines pre-limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #operaciones matriciales y con vectores\n",
    "import pandas as pd #tratamiento de datos\n",
    "import matplotlib.pyplot as plt #gráficos\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression # modelos lineales\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split #metodo de particionamiento de datasets para evaluación\n",
    "from sklearn.model_selection import cross_val_score,cross_validate #protocolo de evaluación\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"DatosTelco.csv\", delimiter = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valoresCasa = d.CASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"GREEN\">Baseline GLOBAL</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"ESTADO\",data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=d[\"ESTADO\"],columns=\"count\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.ESTADO.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**De lo anterior podemos decir que nuestro baseline sera escoger los RETIRADOS con un % del 50,3%** \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"GREEN\">Baseline x GENERO</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.GENERO.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **PARA LOS HOMBRES...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hombres = d.loc[(d.GENERO == \"Hombre\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hombres.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"ESTADO\",data=hombres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=hombres[\"ESTADO\"],columns=\"count\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**El BASELINE en el caso de los HOMBRES seria escoger los RETIRADOS con un % del 50,2%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **PARA LAS MUJERES ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujeres = d.loc[(d.GENERO == \"Mujer\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujeres.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"ESTADO\",data=mujeres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=mujeres[\"ESTADO\"],columns=\"count\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**El BASELINE en el caso de las MUJERES seria escoger los RETIRADOS con un % del 50,4%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"RED\">CONCLUSION</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personalmente creeria que si, ya que los hombres pueden tener gustos o caracteristicas diferentes a las mujeres, en cuanto a las razones del porque se han desvinculado de la compañia telefonica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ademas, puede que alguno de los 2 generos se deje tentar mucho mas facil por ofertas de otras compañias, o incluso, que perciba la atención en cuanto a servicio al cliente de diferentes maneras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En suma a lo anterior, nos puede permitir como compañia que logremos generar ofertas o planes hacia un genero en especifico, de tal forma que logremos disminuir la cantidad de RETIRADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Análisis de los problemas de calidad de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.describe(include = \"all\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos cuantos registros deberian haber:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.loc[d.ESTADO.isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.loc[d.CASA.isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.loc[d.SOBRECARGO.isna()].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "procedemos a borrar los NA correspondientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d[~d.ESTADO.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d[~d.CASA.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d[~d.SOBRECARGO.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.loc[d.columns.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DESPUES DE LA ENTREGA ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busqueda de valores negativos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay algunas columnas en las cuales se puede identificar valores negativos en sus **MIN**, por ende, vamos a listar el numero de registros con este defecto con el fin de evaluar el paso a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.loc[d.CASA < 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.loc[d.MESES < 0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como son tan pocos registros, los convertiremos a NaN y procederemos a borrarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d[~(d['CASA'] < 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d[~(d['MESES'] < 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busqueda de valores atipicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ibx = d.boxplot(column='INGRESOS');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('INGRESOS')\n",
    "plt.hist(d.INGRESOS, bins = 60)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cbx = d.boxplot(column='CASA');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('CASA')\n",
    "plt.hist(d.CASA, bins = 60)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De aqui se justifica buscar y borrar los 3 valores que presentan anomalias, ya que estos para un valor de casa son muy exagerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = d.iloc[d['CASA'].argsort()[-3:]]\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxx =values.CASA.values[0]\n",
    "maxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.loc[d.CASA >= maxx ].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d[d.CASA < maxx]\n",
    "d.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que el boxplot ha quedado sin anomalias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cbx = d.boxplot(column='CASA');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('CASA')\n",
    "plt.hist(d.CASA, bins = 60)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDbx = d.boxplot(column='PRECIO_DISPOSITIVO');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('DISPOSITIVO $')\n",
    "plt.hist(d.PRECIO_DISPOSITIVO, bins = 60)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De aqui se justifica buscar y borrar los 3 valores que presentan anomalias, ya que estos para un valor de dispositivos son muy exagerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#values = d.iloc[d['PRECIO_DISPOSITIVO'].argsort()[-3:]]\n",
    "#values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maxx =values.PRECIO_DISPOSITIVO.values[0]\n",
    "#maxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = d[d.PRECIO_DISPOSITIVO < maxx]\n",
    "#d.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cbx = d.boxplot(column='PRECIO_DISPOSITIVO');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.title('DISPOSITIVO $')\n",
    "#plt.hist(d.PRECIO_DISPOSITIVO, bins = 60)\n",
    "#plt.grid(True)\n",
    "#plt.show()\n",
    "#plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cbx = d.boxplot(column='MESES');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('MESES')\n",
    "plt.hist(d.MESES, bins = 60)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cbx = d.boxplot(column='DURACION');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('DURACION')\n",
    "plt.hist(d.DURACION, bins = 60)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cbx = d.boxplot(column='SOBRECARGO');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('SOBRECARGO')\n",
    "plt.hist(d.SOBRECARGO, bins = 60)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cbx = d.boxplot(column='SALDO_RESTANTE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('SALDO_RESTANTE')\n",
    "plt.hist(d.SALDO_RESTANTE, bins = 60)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cbx = d.boxplot(column='SATISFACCION');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('SATISFACCION')\n",
    "plt.hist(d.SATISFACCION, bins = 60)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dStandard = d.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dStandard[['INGRESOS','CASA','PRECIO_DISPOSITIVO','MESES','DURACION','SOBRECARGO','SALDO_RESTANTE','SATISFACCION']] = scaler.fit_transform(dStandard[['INGRESOS','CASA','PRECIO_DISPOSITIVO','MESES','DURACION','SOBRECARGO','SALDO_RESTANTE','SATISFACCION']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(ncols=2, figsize =(30,10))\n",
    "ax1.set_title(\"Antes de escalar\")\n",
    "sns.kdeplot(d.INGRESOS, ax = ax1)\n",
    "sns.kdeplot(d.CASA, ax = ax1)\n",
    "sns.kdeplot(d.PRECIO_DISPOSITIVO, ax = ax1)\n",
    "sns.kdeplot(d.MESES, ax = ax1)\n",
    "sns.kdeplot(d.DURACION, ax = ax1)\n",
    "sns.kdeplot(d.SOBRECARGO, ax = ax1)\n",
    "sns.kdeplot(d.SALDO_RESTANTE, ax = ax1)\n",
    "sns.kdeplot(d.SATISFACCION, ax = ax1)\n",
    "ax2.set_title(\"Despues de escalar\")\n",
    "sns.kdeplot(dStandard.INGRESOS, ax = ax2)\n",
    "sns.kdeplot(dStandard.CASA, ax = ax2)\n",
    "sns.kdeplot(dStandard.PRECIO_DISPOSITIVO, ax = ax2)\n",
    "sns.kdeplot(dStandard.MESES, ax = ax2)\n",
    "sns.kdeplot(dStandard.DURACION, ax = ax2)\n",
    "sns.kdeplot(dStandard.SOBRECARGO, ax = ax2)\n",
    "sns.kdeplot(dStandard.SALDO_RESTANTE, ax = ax2)\n",
    "sns.kdeplot(dStandard.SATISFACCION, ax = ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de problemas encontrados, acciones tomadas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [**ESTADO**] [Faltan registros]: [Borrar los registros ya que 5/23162 no es tan significativo]\n",
    "2. [**CASA**] [Faltan registros]: [Borrar los registros ya que 100/23162 no es tan significativo]\n",
    "3. [**SOBRECARGO**] [Faltan registros]: [Borrar los registros ya que 3/23162 no es tan significativo]\n",
    "--- Despues de la entrega ---\n",
    "4. [**CASA**] [Valores negativos]: [Borrar los registros ya que 20/23162 no es tan significativo]\n",
    "5. [**MESES**] [Valores Negativos]: [Borrar los registros ya que 153/23162 no es tan significativo]\n",
    "6. [**CASA**] [Anomalias]: [Borrar los registros ya que 3/23162 no es tan significativo]\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>ENTREGA SEGUNDA PARTE</font> - <font color='blue'> POST-CLASE </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EN CASA, PARA ENTREGAR: \n",
    "3. <font color='red'>Para arreglar un problema existente en la variable CASA: (1.0)\n",
    "    * utilice un modelo de regresión lineal (use el modelo sklearn.linear_model.LinearRegression, no use statsmodels)\n",
    "    * considere solo las demas variables NUMÉRICAS como variables predictivas\n",
    "    * cree el mejor modelo que utilice 1 solo variable, calcule el R2 ajustado e interprételo\n",
    "    * utilice holdout (70/30) como protocolo de evaluación\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Valores faltantes de CASA: modelo de regresión lineal usando holdout y forward stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escogemos las variables cuantitativas mas relevantes a simple vista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_vars = ['INGRESOS', 'SALDO_RESTANTE', 'PRECIO_DISPOSITIVO', 'MESES', 'DURACION','SOBRECARGO','SATISFACCION']\n",
    "dep_vars = ['CASA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_data = dStandard[indep_vars]\n",
    "dep_data = dStandard[dep_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(indep_data, dep_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression(normalize=True)\n",
    "regr.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var, coef in zip(indep_vars, np.squeeze(regr.coef_)):\n",
    "    print(\"{}: {}\".format(var, coef))\n",
    "print(\"intercepción: {}\".format(np.squeeze(regr.intercept_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_pred = regr.predict(train_x)\n",
    "test_y_pred = regr.predict(test_x)\n",
    "print(train_y_pred.shape)\n",
    "print(test_y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **bondad de ajuste** de un modelo estadístico describe lo bien que se ajusta un conjunto de observaciones. Las medidas de bondad en general resumen la discrepancia entre los valores observados y los valores esperados en el modelo de estudio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **MSE** : Promedio de los errores al cuadrado.\n",
    "2. **R2** : refleja la bondad del ajuste de un modelo a la variable que pretender explicar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE (train): %.4f\" % mean_squared_error(train_y, train_y_pred))\n",
    "print(\"MSE (test) : %.4f\" % mean_squared_error(test_y, test_y_pred))\n",
    "print('R2  (train): %.4f' % r2_score(train_y, train_y_pred))\n",
    "print('R2  (test) : %.4f' % r2_score(test_y, test_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x2 = sm.add_constant(train_x)\n",
    "print(train_x2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodel para pre-visualizacion (solo tomado como ejemplo para analisis futuros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloStats = sm.OLS(train_y, train_x2)\n",
    "results = modeloStats.fit();\n",
    "#Consultamos la calidad del modelo a partir de sus estadísticas\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PODEMOS CONSIDERAR QUE LAS VARIABLES MAS SIGNIFICATIVAS SON** :\n",
    "\n",
    "* INGRESOS\n",
    "* PRECIO_DISPOSITIVO\n",
    "\n",
    "P < 0,05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Resources/Statsmodel.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación del statsmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Equilibrado R-cuadrado** refleja el ajuste del modelo. Los valores de R cuadrado varían de 0 a 1, donde un valor más alto generalmente indica un mejor ajuste, suponiendo que se cumplan ciertas condiciones.\n",
    "\n",
    "* El **coeficiente constante** es su intersección en Y. Significa que si los coeficientes de tasa de interés y tasa de desempleo son cero, entonces la salida esperada (es decir, la Y) sería igual al coeficiente constante.\n",
    "\n",
    "* El **coeficiente de tasa de interés** representa el cambio en la salida Y debido a un cambio de una unidad en la tasa de interés (todo lo demás se mantuvo constante\n",
    "\n",
    "* El **coeficiente Unemployment_Rate** representa el cambio en la producción Y debido a un cambio de una unidad en la tasa de desempleo (todo lo demás se mantuvo constante)\n",
    "std err  refleja el nivel de precisión de los coeficientes. Cuanto más bajo es, mayor es el nivel de precisión\n",
    "\n",
    "* **P> | t | es el valor de p** . Un valor p de menos de 0.05 se considera estadísticamente significativo\n",
    "\n",
    "* El **intervalo de confianza** representa el rango en el que es probable que disminuyan nuestros coeficientes (con una probabilidad del 95%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la matriz de correlaciones\n",
    "corr = train_x.join(train_y).corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "sns.heatmap(corr, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada cuadrado muestra la correlación entre las variables en cada eje. La correlación varía de -1 a +1. Los valores más cercanos a cero significan que no hay una tendencia lineal entre las dos variables. Cuanto más cerca de 1 sea la correlación, más positivamente están correlacionadas; es decir, a medida que uno aumenta, también lo hace el otro y cuanto más cerca de 1 más fuerte es esta relación. Una correlación más cercana a -1 es similar, pero en lugar de que ambas aumenten, una variable disminuirá a medida que la otra aumenta. Las diagonales son todas 1 / verde oscuro porque esos cuadrados están correlacionando cada variable consigo misma (por lo que es una correlación perfecta). Por lo demás, cuanto mayor sea el número y más oscuro el color, mayor será la correlación entre las dos variables. La gráfica también es simétrica respecto a la diagonal ya que las mismas dos variables se están emparejando juntas en esos cuadrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sin necesidad del statsmodel, podemos utilizar la grafica anterior para inferir cuales son las mejores variables del modelo, siendo estas INGRESOS, SALDO_RESTANTE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"GREEN\">FORWARD STEPWISE</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Forward**: se prueba una a una con las variables independientes aún no escogidas y se evalúa el modelo conjuntamente con las variables previamente escogidas, escogiendo la mejor. Se para cuando la medida de bondad de ajuste no mejore.\n",
    "* **Backward**: sigue un proceso contrario al forward, empezando con todas las variables y\n",
    "eliminando la variable que al no considerarla optimice la medida de bondad de ajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dStandard.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allVars =['MESES','DURACION','SALDO_RESTANTE','SOBRECARGO','SATISFACCION','INGRESOS','PRECIO_DISPOSITIVO']\n",
    "#significative_vars = ['INGRESOS','PRECIO_DISPOSITIVO']\n",
    "dep_data = dStandard['CASA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creare un dataframe vacio para irlo llenando :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise =  pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for var in significative_vars:\n",
    "#    stepwise[var] = dStandard[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stepwise.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular el **R2** inicial :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x, test_x, train_y, test_y = train_test_split(stepwise, dep_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regr = LinearRegression(normalize=True)\n",
    "#regr.fit(train_x, train_y)\n",
    "#test_y_pred = regr.predict(test_x)\n",
    "#r2 = r2_score(test_y, test_y_pred)      \n",
    "#print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = 0\n",
    "mejorModelo = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columna in allVars:\n",
    "    stepwise[columna] = dStandard[columna]\n",
    "    train_x, test_x, train_y, test_y = train_test_split(stepwise, dep_data, test_size=0.3, random_state=42)\n",
    "    regr = LinearRegression(normalize=True)\n",
    "    regr.fit(train_x, train_y)\n",
    "    test_y_pred = regr.predict(test_x)\n",
    "#   r2_actual = r2_score(test_y, test_y_pred)\n",
    "    r2_adj= 1- (1-r2_score(test_y, test_y_pred))*(len(test_y)-1) / (len(test_y) - test_x.shape[1] - 1)\n",
    "    print(\"---\")\n",
    "    print(\"R2_Calculado : \" + str(r2_adj))\n",
    "    if( r2_adj > r2 ):\n",
    "        mejorModelo = \"El mejor modelo es con la variable : \" + columna\n",
    "        r2 = r2_adj\n",
    "        print(\"Nuevo R2 : \" + str(r2))\n",
    "    stepwise = stepwise.drop([columna],axis=1)\n",
    "    print(\"---\")\n",
    "print(mejorModelo + \" con : \" + str(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo quedo conformado por :\n",
    "\n",
    "* **INGRESOS** con el **99,34%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo cual representa un R2 Ajustado bastante bueno, casi apuntando al **100%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** El valor del R2 ajustado corrige el valor del R2 con respecto a la complejidad dada por el número de variables independientes utilizadas, y permite comparar modelos de diferente número de predictores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modelos de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puntos a desarrollar:\n",
    "\n",
    "<font color='red'>El objetivo final es identificar los clientes más propensos a irse de la compañía, con el fin de poder realizar campañas de fidelización. Para tal propósito, se ha decidido buscar el mejor modelo entre **K-NN** y **Naïve Bayes**, pero **solo considerando las variables predictivas numéricas**. </font>\n",
    "\n",
    "1. <font color='red'> Establezca el **protocolo de evaluación** y la métrica de evaluación más adecuados para la construcción de los modelos de clasificación (0.3)</font>\n",
    "\n",
    "2. <font color='red'> Construya del mejor modelo **K-NN**, buscando el mejor valor de K (subir hasta un valor de K=25) (1.1)</font>\n",
    "\n",
    "3. <font color='red'> Construya del mejor modelo **Naïve Bayes** (use la clase GaussianNB), buscando el mejor valor del suavizador de Laplace (var_smoothing) (0.7)</font>\n",
    "\n",
    "4. <font color='red'> Compárelos (métricas, matriz de confusión), escoja el mejor, y concluya (0.3)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 <font color=\"BLUE\">KNN, NB  y Protocolo de evaluación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cambiare los valores de **ESTADO** de categorica a float donde :\n",
    "\n",
    "        0 sera VINCULADO\n",
    "        1 sera RETIRADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dStandard.loc[(d.ESTADO == \"VINCULADO\"),\"ESTADO\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dStandard.loc[(d.ESTADO == \"RETIRADO\"),\"ESTADO\"]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiare los valores de **GENERO** a numericos, donde :\n",
    "\n",
    "        0 sera HOMBRE\n",
    "        1 sera MUJER\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dStandard.loc[(d.GENERO == \"Hombre\"),\"GENERO\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dStandard.loc[(d.GENERO == \"Mujer\"),\"GENERO\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dStandardModel = dStandard.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dStandardModel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borrare el ID, ya que no es una variable significativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dStandardModel['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dStandardModel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color=\"purple\">**2.2 ::KNN::**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2.1 KNN with all Dataset to extract best value of K**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el dataset completo para evaluar el modelo **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dStandardModel\n",
    "y = dStandardModel.ESTADO\n",
    "#yReshape = dStandardModel.ESTADO.values.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos desde k=1 hasta k=25, seleccionando los numeros **impares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = []\n",
    "for i in range(1,26):\n",
    "    if (i%2) != 0:\n",
    "        numbers.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numbers:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x, y)\n",
    "    y_pred = knn.predict(x)\n",
    "    print(\"K=\" + str(i) + \"  >>>  \"+ str(metrics.accuracy_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Podemos observar que el mejor modelo de k fue k=3 con un porcentaje del 99,92%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.2.1.1 Metricas y matriz de confusión knn with all dataset k=3** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x, y)\n",
    "y_pred = knn.predict(x)\n",
    "print(\"K=3  >>>  \"+ str(metrics.accuracy_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm= metrics.confusion_matrix(y, y_pred)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title(\"Matriz de confusión para K=3\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(3)\n",
    "plt.xticks(tick_marks, ['0','1']) #duda aqui\n",
    "plt.yticks(tick_marks, ['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)\n",
    "print(\"Exactitud: \", metrics.accuracy_score(y, y_pred))\n",
    "print(\"Kappa    : \", metrics.cohen_kappa_score(y, y_pred))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Metricas para la categoría \", \"0\")\n",
    "print(\"Precisión     : \", metrics.precision_score(y, y_pred, labels=[0], average='macro'))\n",
    "print(\"Recall        : \", metrics.recall_score(y, y_pred, labels=[0], average='macro'))\n",
    "VN = np.sum(cm[1:3,1:3])\n",
    "FP = np.sum(cm[0,1:3])\n",
    "specificity = VN/(VN+FP)\n",
    "print(\"Especificidad : \", specificity)\n",
    "print(\"F1-score      : \", metrics.f1_score(y, y_pred, labels=[0], average='macro'))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Metricas para la categoría \", \"1\")\n",
    "print(\"Precisión     : \", metrics.precision_score(y, y_pred, labels=[1], average='macro'))\n",
    "print(\"Recall        : \", metrics.recall_score(y, y_pred, labels=[1], average='macro'))\n",
    "VN = 98\n",
    "FP = 2\n",
    "specificity = VN/(VN+FP)\n",
    "print(\"Especificidad : \", specificity)\n",
    "print(\"F1-score      : \", metrics.f1_score(y, y_pred, labels=[1], average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 **Protocolos de evaluación**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2.1 **Holdout (Split)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a separar el dataset en 2 partes: 70% de los datos se van a utilizar para aprender, 30% para evaluar el modelo de clasificación.\n",
    "Utilizamos el método *train_test_split* de scikit-learn, que se encarga de hacer el particionamiento aleatorio: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=12345, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape[0])\n",
    "print(X_test.shape[0])\n",
    "print(y_train.shape[0])\n",
    "print(y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestAcc = 0\n",
    "accuracyKNN = \"\"\n",
    "acc_train_vec=[]\n",
    "acc_test_vec=[]\n",
    "for k in numbers:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_train)\n",
    "    acc_train_vec.append(metrics.accuracy_score(y_train, y_pred))\n",
    "    y_pred = knn.predict(X_test)\n",
    "    acc_test_vec.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    value = metrics.accuracy_score(y_test, y_pred)\n",
    "    if(value > bestAcc and k>1):\n",
    "        bestAcc = value\n",
    "        accuracyKNN = \"Mejor Acurracy : \" + str(bestAcc) + \" con k= \" + str(k)\n",
    "\n",
    "print(acc_train_vec)\n",
    "print(\"---\")\n",
    "print(acc_test_vec)\n",
    "print(k_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "ax = plt.gca() # get current axis\n",
    "plt.plot(numbers, acc_train_vec)\n",
    "plt.plot(numbers, acc_test_vec)\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.axis('tight')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Evolución de le exactitud vs complejidad del modelo k-nn (valor de k más pequeño)')\n",
    "plt.legend(['train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando el protocolo de evaluación **HOLDOUT** podemos observar que nuestro **K=3** sigue siendo el mejor, pero disminuyo de **99,92%** a **99,59%**, ya que en este no estamos evaluando con todo el dataframe, sino con una parte de entrenamiento y una de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2.2 <font color = \"GREEN\"> **Train of KNN best model (K=3) with HOLDOUT** </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN** con un k=3, ha sido muy bueno hasta el momento. Es hora de evaluarlo con el holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"K=3>>>  \"+ str(metrics.accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)\n",
    "print(\"Exactitud: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Kappa    : \", metrics.cohen_kappa_score(y_test, y_pred))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Metricas para la categoría \", \"0\")\n",
    "print(\"Precisión     : \", metrics.precision_score(y_test, y_pred, labels=[0], average='macro'))\n",
    "print(\"Recall        : \", metrics.recall_score(y_test, y_pred, labels=[0], average='macro'))\n",
    "VN = np.sum(cm[1:3,1:3])\n",
    "FP = np.sum(cm[0,1:3])\n",
    "specificity = VN/(VN+FP)\n",
    "print(\"Especificidad : \", specificity)\n",
    "print(\"F1-score      : \", metrics.f1_score(y_test, y_pred, labels=[0], average='macro'))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Metricas para la categoría \", \"1\")\n",
    "print(\"Precisión     : \", metrics.precision_score(y_test, y_pred, labels=[1], average='macro'))\n",
    "print(\"Recall        : \", metrics.recall_score(y_test, y_pred, labels=[1], average='macro'))\n",
    "VN = 98\n",
    "FP = 2\n",
    "specificity = VN/(VN+FP)\n",
    "print(\"Especificidad : \", specificity)\n",
    "print(\"F1-score      : \", metrics.f1_score(y_test, y_pred, labels=[1], average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm= metrics.confusion_matrix(y_test, y_pred)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title(\"Matriz de confusión para K=3\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(3)\n",
    "plt.xticks(tick_marks, ['0','1']) #duda aqui\n",
    "plt.yticks(tick_marks, ['0','1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 <font color=\"PURPLE\">Modelo Naïve Bayes with HOLDOUT</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el mismo **HOLDOUT** del **KNN** para poder evaluar ambos modelos conjuntamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Naive Bayes without Var_Smoothing (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=12345, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB(var_smoothing= 1)\n",
    "nb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_train)\n",
    "print(\"Train : \" + str(metrics.accuracy_score(y_train, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_test)\n",
    "print(\"Test : \" + str(metrics.accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el modelo de **Naive Bayes** obtuvimos en el test un **90,79% de precisión** con el **Var_Smoothing** igual a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm= metrics.confusion_matrix(y_test, y_pred)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title(\"Matriz de confusión para Gaussian Naive Bayes\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(3)\n",
    "plt.xticks(tick_marks, ['0','1']) #duda aqui\n",
    "plt.yticks(tick_marks, ['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)\n",
    "print(\"Exactitud: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Kappa    : \", metrics.cohen_kappa_score(y_test, y_pred))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Metricas para la categoría \", \"0\")\n",
    "print(\"Precisión     : \", metrics.precision_score(y_test, y_pred, labels=[0], average='macro'))\n",
    "print(\"Recall        : \", metrics.recall_score(y_test, y_pred, labels=[0], average='macro'))\n",
    "VN = np.sum(cm[1:3,1:3])\n",
    "FP = np.sum(cm[0,1:3])\n",
    "specificity = VN/(VN+FP)\n",
    "print(\"Especificidad : \", specificity)\n",
    "print(\"F1-score      : \", metrics.f1_score(y_test, y_pred, labels=[0], average='macro'))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Metricas para la categoría \", \"1\")\n",
    "print(\"Precisión     : \", metrics.precision_score(y_test, y_pred, labels=[1], average='macro'))\n",
    "print(\"Recall        : \", metrics.recall_score(y_test, y_pred, labels=[1], average='macro'))\n",
    "VN = 98\n",
    "FP = 2\n",
    "specificity = VN/(VN+FP)\n",
    "print(\"Especificidad : \", specificity)\n",
    "print(\"F1-score      : \", metrics.f1_score(y_test, y_pred, labels=[1], average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.2 Gaussian NB with Var_Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2.1 Evaluando los mejores var_smoothing (laplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.arange(0.1,1,0.01)\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestAcc = 0\n",
    "accuracyNB = \"\"\n",
    "acc_train_vec=[]\n",
    "acc_test_vec=[]\n",
    "for i in numbers:\n",
    "    nb = GaussianNB(var_smoothing= round(i,2))\n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_train)\n",
    "    acc_train_vec.append(metrics.accuracy_score(y_train, y_pred))\n",
    "    y_pred = nb.predict(X_test)\n",
    "    acc_test_vec.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    value = metrics.accuracy_score(y_test, y_pred) \n",
    "    if(value > bestAcc):\n",
    "        bestAcc = value\n",
    "        acurracyNB = \"Mejor Acurracy : \" + str(bestAcc) + \" con var_smoothing : \" + str(round(i,2))\n",
    "    \n",
    "print(acc_train_vec)\n",
    "print(\"---\")\n",
    "print(acc_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acurracyNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "ax = plt.gca() # get current axis\n",
    "plt.plot(numbers, acc_train_vec)\n",
    "plt.plot(numbers, acc_test_vec)\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.axis('tight')\n",
    "plt.xlabel('Var_Smoothing')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Evolución de le exactitud vs complejidad del modelo Gaussian NB (valor de Var_Smoothing)')\n",
    "plt.legend(['train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiis del intervalo 0.1-0.15 en la grafica anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la anterior imagen podemos ver que en el intervalo desde 0.1 hasta intermedio de llegada a 0.2 , existe una curva que implica que el aprendizaje es muy bueno en esa zona, pero luego llega a un punto donde el modelo empieza a perder accuracy, por ende vamos a buscar un poco mas que esta sucediendo en este lado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.arange(0.01,0.15,0.001)\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestAcc = 0\n",
    "accuracyNB = \"\"\n",
    "acc_train_vec=[]\n",
    "acc_test_vec=[]\n",
    "for i in numbers:\n",
    "    nb = GaussianNB(var_smoothing= round(i,2))\n",
    "    nb.fit(X_train, y_train)\n",
    "    y_pred = nb.predict(X_train)\n",
    "    acc_train_vec.append(metrics.accuracy_score(y_train, y_pred))\n",
    "    y_pred = nb.predict(X_test)\n",
    "    acc_test_vec.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    value = metrics.accuracy_score(y_test, y_pred) \n",
    "    if(value > bestAcc):\n",
    "        bestAcc = value\n",
    "        acurracyNB = \"Mejor Acurracy : \" + str(bestAcc) + \" con var_smoothing : \" + str(round(i,2))\n",
    "    \n",
    "print(acc_train_vec)\n",
    "print(\"---\")\n",
    "print(acc_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acurracyNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "ax = plt.gca() # get current axis\n",
    "plt.plot(numbers, acc_train_vec)\n",
    "plt.plot(numbers, acc_test_vec)\n",
    "ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.axis('tight')\n",
    "plt.xlabel('Var_Smoothing')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Evolución de le exactitud vs complejidad del modelo Gaussian NB (valor de Var_Smoothing)')\n",
    "plt.legend(['train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"GREEN\"> Gaussian NB con Var_Smoothing = 0.04</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB(var_smoothing= 0.04)\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "acuraccy = metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuraccy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm= metrics.confusion_matrix(y_test, y_pred)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title(\"Matriz de confusión para Gaussian Naive Bayes laplace = 0.04\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(3)\n",
    "plt.xticks(tick_marks, ['0','1']) #duda aqui\n",
    "plt.yticks(tick_marks, ['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)\n",
    "print(\"Exactitud: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Kappa    : \", metrics.cohen_kappa_score(y_test, y_pred))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Metricas para la categoría \", \"0\")\n",
    "print(\"Precisión     : \", metrics.precision_score(y_test, y_pred, labels=[0], average='macro'))\n",
    "print(\"Recall        : \", metrics.recall_score(y_test, y_pred, labels=[0], average='macro'))\n",
    "VN = np.sum(cm[1:3,1:3])\n",
    "FP = np.sum(cm[0,1:3])\n",
    "specificity = VN/(VN+FP)\n",
    "print(\"Especificidad : \", specificity)\n",
    "print(\"F1-score      : \", metrics.f1_score(y_test, y_pred, labels=[0], average='macro'))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Metricas para la categoría \", \"1\")\n",
    "print(\"Precisión     : \", metrics.precision_score(y_test, y_pred, labels=[1], average='macro'))\n",
    "print(\"Recall        : \", metrics.recall_score(y_test, y_pred, labels=[1], average='macro'))\n",
    "VN = 98\n",
    "FP = 2\n",
    "specificity = VN/(VN+FP)\n",
    "print(\"Especificidad : \", specificity)\n",
    "print(\"F1-score      : \", metrics.f1_score(y_test, y_pred, labels=[1], average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Comparación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si comparamos los modelos que estan en **VERDE**, donde utilizamos el **Gaussian NB** con **var_smoothing = 0.04** y el **KNN** con **K=3**, podemos observar lo siguiente:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        En el KNN obtuvimos un accuracy del K=3>>>  0.995920745920746"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        En el Gaussian NB obtuvimos un accuracy del 0.9983974358974359 con var_smoothing del 0.04\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista podriamos escoger el **Gaussian NB**, ya que obtuvimos un accuracy bastante elevado, pero , analisemos las otras metricas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Exactitud**:  0.995920745920746\n",
    "* **Kappa**    :  0.9918410935461383"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metricas para la categoría  0\n",
    "\n",
    "* **Precisión**     :  0.9961843263868506\n",
    "* **Recall**        :  0.9955998826635377\n",
    "* **Especificidad** :  0.999131718329426\n",
    "* **F1-score**      :  0.9958920187793427"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metricas para la categoría  1\n",
    "\n",
    "* **Precisión**     :  0.9956609777263523\n",
    "* **Recall**        :  0.9962373371924746\n",
    "* **Especificidad** :  0.98\n",
    "* **F1-score**      :  0.9959490740740741"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian NB var_Smoothing = 0.04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Exactitud**:  0.9983974358974359\n",
    "* **Kappa**    :  0.9967946589876142"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metricas para la categoría  0\n",
    "\n",
    "* **Precisión**     :  1.0\n",
    "* **Recall**        :  0.9967732472865943\n",
    "* **Especificidad** :  0.9968263127524524\n",
    "* **F1-score**      :  0.9983840164536506"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metricas para la categoría  1\n",
    "\n",
    "* **Precisión**     :  0.9968263127524524\n",
    "* **Recall**        :  1.0\n",
    "* **Especificidad** :  0.98\n",
    "* **F1-score**      :  0.9984106343014015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"GREEN\">Conclusión</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian NB** es el modelo que deberiamos escoger, ya que a comparación del KNN , nos ofrece :\n",
    "\n",
    "* Un accuracy mas elevado\n",
    "* Una tasa de recall, el cual implica el numero de **positivos reales** que puede identificar por cada categoria, mas elevado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
